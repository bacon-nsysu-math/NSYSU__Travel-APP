import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import streamlit as st
import os
import requests
import datetime
from geopy.geocoders import Nominatim
from geopy.exc import GeocoderTimedOut

# å®šç¾©æ¨™ç±¤æ˜ å°„ (å°‡ CSV é›œäº‚æ¨™ç±¤æ­¸é¡ç‚ºæ¨™æº–é¡åˆ¥)
TAG_MAPPING = {
    "ğŸ¯ æ­·å²å¤è¹Ÿ": ["å¤è¹Ÿ", "æ­·å²", "çœ·æ‘", "è€è¡—", "ç´€å¿µ", "å»¢å¢Ÿé¢¨", "å­”å»Ÿ", "æ›¸é™¢"],
    "ğŸ¨ è—æ–‡æ–‡å‰µ": ["è—æ–‡", "æ–‡å‰µ", "ç¾è¡“é¤¨", "å±•è¦½", "éŸ³æ¨‚", "é–±è®€", "è¨­è¨ˆ", "é›»å½±", "åœ–æ›¸é¤¨", "è—è¡“"],
    "ğŸ¡ è¦ªå­æ¨‚åœ’": ["è¦ªå­", "æ¨‚åœ’", "è§€å…‰å·¥å» ", "é«”é©—", "DIY", "å‹•ç‰©", "ç§‘æ™®"],
    "â›°ï¸ å±±æ—æ­¥é“": ["ç™»å±±", "å±±", "æ­¥é“", "å¤é“", "åŸä½æ°‘", "æº«æ³‰", "è´è¶", "æ³¥ç«å±±", "åœ°è³ª", "æ£®æ—", "èŒ¶åœ’", "ç”Ÿæ…‹"],
    "ğŸŒŠ æµ·æ¸¯æ°´åŸŸ": ["æµ·é‚Š", "æ¸¯", "ç¢¼é ­", "éŠèˆ¹", "ç©æ°´", "æ¹–", "ç€‘å¸ƒ", "æ¿•åœ°", "æ¿±æµ·", "æ°´æ¯"],
    "ğŸ›ï¸ é€›è¡—ç¾é£Ÿ": ["è³¼ç‰©", "å•†åœˆ", "ç¾é£Ÿ", "å¤œå¸‚", "å°åƒ", "ç™¾è²¨", "æµ·é®®"],
    "ğŸ“¸ ç¶²ç¾æ‰“å¡": ["æ‰“å¡é»", "æ™¯è§€", "å¤œæ™¯", "åœ°æ¨™", "å½©ç¹ª", "è£ç½®è—è¡“", "å»ºç¯‰", "å¤•é™½"],
    "ğŸš‚ éµé“äº¤é€š": ["éµé“", "è»Šç«™", "ç«è»Š", "æ·é‹", "è¼•è»Œ", "é£›æ©Ÿ"],
    "ğŸ™ å®—æ•™å·¡ç¦®": ["å»Ÿå®‡", "æ•™å ‚", "æ•™æœƒ", "å¤©åå®®", "ä½›å…‰å±±", "ä¿®é“é™¢"],
    "ğŸš² å–®è»Šæ¼«éŠ": ["è‡ªè¡Œè»Š", "å–®è»Š", "éµé¦¬"],
    "ğŸ›– åŸæ°‘éƒ¨è½": ["åŸä½æ°‘", "éƒ¨è½", "åŸé„‰", "ç¥­å…¸", "çŸ³æ¿å±‹", "ç‰ç’ƒç ", "é‚£ç‘ªå¤", "èŒ‚æ—", "æ¡ƒæº"],
    "ğŸ˜ï¸ çœ·æ‘æ•…äº‹": ["çœ·æ‘", "è»äº‹", "è€å±‹", "æ—¥å¼", "æµ·è»", "ç©ºè»", "é™¸è»"]
}

@st.cache_data
def load_data():
    """è®€å–æ™¯é»è³‡æ–™åº« CSV æª”æ¡ˆ"""
    file_path = 'data/data.csv'
    try:
        df = pd.read_csv(file_path, encoding='utf-8')
    except Exception as e:
        st.error(f"ç„¡æ³•è®€å–è³‡æ–™åº«ï¼Œè«‹ç¢ºèª '{file_path}' æ˜¯å¦å­˜åœ¨ã€‚éŒ¯èª¤: {e}")
        return pd.DataFrame()

    if 'tags' in df.columns: df['tags'] = df['tags'].fillna('')
    if 'image_url' not in df.columns: df['image_url'] = ""
    if 'latitude' not in df.columns: df['latitude'] = 0.0
    if 'longitude' not in df.columns: df['longitude'] = 0.0
    if 'district' not in df.columns: df['district'] = "æœªåˆ†é¡"
    else: df['district'] = df['district'].fillna("æœªåˆ†é¡")

    # ç”¢ç”Ÿ mapped_tags
    def get_mapped_tags(raw_tags):
        mapped = set()
        for tag in str(raw_tags).split(','):
            t = tag.strip()
            for category, keywords in TAG_MAPPING.items():
                if t in keywords or any(k in t for k in keywords):
                    mapped.add(category)
        return list(mapped)
    
    df['mapped_tags'] = df['tags'].apply(get_mapped_tags)
    return df

@st.cache_data
def load_night_markets():
    """è®€å–å¤œå¸‚è³‡æ–™åº« CSV"""
    # [Fix] Point to the correct data folder
    file_path = os.path.join(os.path.dirname(__file__), "data", "night_markets.csv")
    
    if not os.path.exists(file_path):
        # Fallback to root if data folder version missing (backward compatibility)
        file_path = os.path.join(os.path.dirname(__file__), "night_markets.csv")
        
    if not os.path.exists(file_path):
        return pd.DataFrame()
        
    try:
        df = pd.read_csv(file_path)
        if 'image_url' not in df.columns: df['image_url'] = ""
        df['image_url'] = df['image_url'].fillna("")
        
        # Default Taiwan Night Market Image
        default_img = "https://images.unsplash.com/photo-1528164344705-47542687000d?q=80&w=600&auto=format&fit=crop"
        
        # Apply default to empty strings
        df.loc[df['image_url'].str.strip() == "", 'image_url'] = default_img
        return df
    except Exception as e:
        print(f"Error loading night markets: {e}")
        return pd.DataFrame()

def calculate_recommendations(df, user_prefs, specific_tags=[], days=1):
    """è¨ˆç®—æ¨è–¦æ™¯é»"""
    if df.empty: return None

    # 1. è¨ˆç®—é¡åˆ¥åˆ†æ•¸ (æ ¹æ“š mapped_tags)
    # 1. è¨ˆç®—é¡åˆ¥åˆ†æ•¸ (æ ¹æ“š mapped_tags)
    def calculate_score(row):
        score = 0
        tags = row['mapped_tags']
        
        # åŸºç¤åå¥½æ¬Šé‡ (5å¤§é¢å‘)
        # 1. è‡ªç„¶å…‰è­œ
        if "â›°ï¸ å±±æ—æ­¥é“" in tags or "ğŸŒŠ æµ·æ¸¯æ°´åŸŸ" in tags or "ğŸ›– åŸæ°‘éƒ¨è½" in tags: 
            score += user_prefs.get('nature', 0.5)
            
        # 2. è€éˆé­‚ (æ­·å²/å®—æ•™)
        if "ğŸ¯ æ­·å²å¤è¹Ÿ" in tags or "ğŸ™ å®—æ•™å·¡ç¦®" in tags or "ğŸ˜ï¸ çœ·æ‘æ•…äº‹" in tags or "ğŸ›– åŸæ°‘éƒ¨è½" in tags:
            score += user_prefs.get('history', 0.5)
            
        # 3. æ–°æ½®æµ (ç¶²ç¾/æ–‡å‰µ)
        if "ğŸ¨ è—æ–‡æ–‡å‰µ" in tags or "ğŸ“¸ ç¶²ç¾æ‰“å¡" in tags or "ğŸ˜ï¸ çœ·æ‘æ•…äº‹" in tags:
            score += user_prefs.get('trend', 0.5)
            
        # 4. ç©æ¨‚æ€§è³ª (è¦ªå­)
        if "ğŸ¡ è¦ªå­æ¨‚åœ’" in tags:
            score += user_prefs.get('fun', 0.5)
            
        # 5. éƒ½å¸‚ç”Ÿæ´» (é€›è¡—/ç¾é£Ÿ)
        if "ğŸ›ï¸ é€›è¡—ç¾é£Ÿ" in tags:
            score += user_prefs.get('urban', 0.5)
        
        # ç‰¹å®šæ¨™ç±¤åŠ æ¬Š (ä¾†è‡ªä½¿ç”¨è€…é¸å–çš„ Pill Tags)
        for t in specific_tags:
            if t in tags:
                score += 0.3 # é¸ä¸­æ¨™ç±¤åŠ åˆ†
        
        return score

    df['score'] = df.apply(calculate_score, axis=1)
    
    # æ­£è¦åŒ–åˆ†æ•¸
    if df['score'].max() > 0:
        df['similarity'] = df['score'] / df['score'].max()
    else:
        df['similarity'] = 0

    # ä¾ç…§åˆ†æ•¸æ’åº
    rec_limit = max(10, days * 6) # å‹•æ…‹é™åˆ¶æ•¸é‡
    recommendations = df.sort_values(by='similarity', ascending=False).head(rec_limit)
    return recommendations

def get_static_map_image(itinerary_data, api_key):
    """å–å¾— Google Static Maps åœ–ç‰‡"""
    if not api_key: return None
    base_url = "https://maps.googleapis.com/maps/api/staticmap?"
    markers_str = ""
    # åªå–å‰ 15 å€‹é»ä»¥å… URL éé•·
    for item in itinerary_data[:15]: 
        # æ³¨æ„ï¼šé€™è£¡å‡è¨­ itinerary_data è£¡é¢é‚„æ²’æœ‰è‡ªå‹•å¡«å…¥ lat/lonï¼Œ
        # å¦‚æœæœªä¾†æœ‰åŠ å…¥ï¼Œå¯ä»¥ç›´æ¥ç”¨ã€‚ç›®å‰æ˜¯ç”¨åç¨±å»çŒœæˆ–å¿½ç•¥ã€‚
        pass
        
    # ç¯„ä¾‹å›å‚³ None (å› éœ€è¦é‡å¯«å®Œæ•´åº§æ¨™é‚è¼¯)
    return None

def create_txt(itinerary, trip_name, total_budget):
    """
    Generates a text file for the itinerary.
    """
    lines = []
    lines.append(f"=== {trip_name} è¡Œç¨‹è¡¨ ===")
    lines.append(f"ç¸½é ç®—: ${total_budget}")
    
    total_cost = sum(item.get('Cost', 0) for item in itinerary)
    lines.append(f"é ä¼°èŠ±è²»: ${total_cost}")
    lines.append(f"å‰©é¤˜é ç®—: ${total_budget - total_cost}")
    lines.append("-" * 30)
    
    # Group by Day
    days = sorted(list(set(item['Day'] for item in itinerary)))
    
    for day in days:
        lines.append(f"\n[Day {day}]")
        day_items = sorted([i for i in itinerary if i['Day'] == day], key=lambda x: x.get('Start', '00:00'))
        
        for item in day_items:
            start = item.get('Start', '00:00')
            end = item.get('End', '00:00')
            name = item['Name']
            cost = item.get('Cost', 0)
            note = item.get('Note', '')
            
            line = f"{start}-{end} | {name} | ${cost}"
            if note:
                line += f" | å‚™è¨»: {note}"
            lines.append(line)
            
            # Sub-budgets if any
            if 'SubBudgets' in item and item['SubBudgets']:
                for sub in item['SubBudgets']:
                     lines.append(f"    - {sub['Category']}: ${sub['Cost']} ({sub.get('Note','')})")
    
    lines.append("\n" + "="*30)
    lines.append("Generated by Travel Planner AI")
    
    return "\n".join(lines).encode('utf-8')

@st.cache_data
def get_coordinates(address):
    """
    ä½¿ç”¨ OpenStreetMap (Nominatim) å°‡åœ°å€è½‰æ›ç‚ºç¶“ç·¯åº¦
    å…·å‚™è‡ªå‹•é™ç´šæœå°‹åŠŸèƒ½ (å®Œæ•´åœ°å€ -> è·¯å -> å¤±æ•—)
    """
    try:
        geolocator = Nominatim(user_agent="kaohsiung_travel_planner_app_v1")
        
        # Helper to ensure region context
        def format_addr(addr):
            # å¼·åˆ¶åŠ ä¸Šå°ç£ï¼Œé¿å…æœå°‹åˆ°ä¸­åœ‹åŒååœ°é»
            prefix = ""
            if "å°ç£" not in addr and "è‡ºç£" not in addr:
                prefix += "å°ç£"
            if "é«˜é›„" not in addr:
                prefix += "é«˜é›„å¸‚"
            
            return f"{prefix}{addr}" if prefix else addr

        # 1. å˜—è©¦å®Œæ•´åœ°å€
        targets = [address]
        
        # 2. å˜—è©¦å»é™¤é–€ç‰Œè™Ÿç¢¼ (ç°¡æ˜“æ­£å‰‡ï¼šå»é™¤æ•¸å­—+è™Ÿ)
        import re
        road_only = re.sub(r'\d+è™Ÿ?', '', address).strip()
        if road_only and road_only != address:
            targets.append(road_only)
            
        # 3. å˜—è©¦å»é™¤ "é«˜é›„å¸‚" ç­‰å‰ç¶´å¾Œçš„é—œéµå­—
        # simple_name = address.replace("é«˜é›„å¸‚", "").replace("å°ç£", "")
        # targets.append(simple_name)

        for target in targets:
            full_query = format_addr(target)
            location = geolocator.geocode(full_query, timeout=10)
            if location:
                return location.latitude, location.longitude
                
        return None
    except Exception as e:
        print(f"Geocoding error: {e}")
        return None
